
---------------INPUT------------------
Enter the dataset name (Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv, ...): Enter the dataset type (DDOS, WEB ATTACK, ...): Enter the shot example type (ZERO-SHOT, FEW-SHOT): Set the number of tests: Set the window size: Set the seed: --------------------------------------

-------------METADATA-----------------
Unique label values: ['BENIGN' 'DDoS']
Number of rows in the dataset: 225746
Percentage of flows labeled BENIGN: 43.29%
Dataset name: Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv
Dataset type: DDOS
Shot example type: ZERO-SHOT
Number of tests: 1
Window size: 1
Set seed: 1234
--------------------------------------

-------------AUTOMATION?--------------
Run automated model comparison on all installed models? (YES/NO): Starting automated testing loop...
Found 8 installed models
--------------------------------------

====================================================================================================
Testing model: deepseek-r1:8b
====================================================================================================

--------------TESTING-----------------
[92mTest #203991: Correct label = benign, Predicted label = benign: âœ”[0m
--------------------------------------

====================================================================================================
Testing model: gemma3:270m
====================================================================================================

--------------TESTING-----------------
[92mTest #203991: Correct label = benign, Predicted label = benign: âœ”[0m
--------------------------------------

====================================================================================================
Testing model: phi3:latest
====================================================================================================

--------------TESTING-----------------
[92mTest #203991: Correct label = benign, Predicted label = benign: âœ”[0m
--------------------------------------

====================================================================================================
Testing model: mistral:latest
====================================================================================================

--------------TESTING-----------------
[0mTest #203991: Correct label = benign, Predicted label = based on the provide...: âœ˜[0m
--------------------------------------

====================================================================================================
Testing model: dolphin3:latest
====================================================================================================

--------------TESTING-----------------
[92mTest #203991: Correct label = benign, Predicted label = benign: âœ”[0m
--------------------------------------

====================================================================================================
Testing model: deepseek-r1:32b
====================================================================================================

--------------TESTING-----------------
[92mTest #203991: Correct label = benign, Predicted label = benign: âœ”[0m
--------------------------------------

====================================================================================================
Testing model: gpt-oss:20b
====================================================================================================

--------------TESTING-----------------
[92mTest #203991: Correct label = benign, Predicted label = benign: âœ”[0m
--------------------------------------

====================================================================================================
Testing model: gemma3:1b
====================================================================================================

--------------TESTING-----------------
[91mTest #203991: Correct label = benign, Predicted label = malicious: âœ˜[0m
--------------------------------------

====================================================================================================
MODEL COMPARISON RESULTS - SORTED BY F1 SCORE
====================================================================================================
Model                     Accuracy     Precision    Recall       F1 Score     MCC       
----------------------------------------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/ubuntu/martinmalensek_diploma/SNIC_Network_Security/scripts/ModelTester.py", line 333, in <module>
    main()
  File "/home/ubuntu/martinmalensek_diploma/SNIC_Network_Security/scripts/ModelTester.py", line 283, in main
    run_automated_tests(dataset, labelIndex, datasetType, shots, numberTests, windowSize, seed)
  File "/home/ubuntu/martinmalensek_diploma/SNIC_Network_Security/scripts/AutomatedTestingLoop.py", line 77, in run_automated_tests
    f"{r['totalTime']:<12.1f}")
KeyError: 'totalTime'
